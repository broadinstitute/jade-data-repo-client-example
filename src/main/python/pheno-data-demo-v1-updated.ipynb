{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates typical initial steps to exploring phenotype distributions. It has been written to be interactive, allowing you to make choices as you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data disclaimer\n",
    "----\n",
    "\n",
    "All data in this notebook (and this workspace) are publicly available thanks to the effort of many dedicated individuals: \n",
    "\n",
    "- Genotype and some phenotypic data were produced by the [1000 Genomes Project (phase 3)](https://www.internationalgenome.org/)\n",
    "\n",
    "- Individual phenotypes were modeling using the [GCTA software](cnsgenomics.com/software/gcta) and variant-level summary statistics from [MAGIC](https://www.magicinvestigators.org/), the [GIANT Consortium](https://portals.broadinstitute.org/collaboration/giant/index.php/Main_Page), the [UK Biobank](https://www.ukbiobank.ac.uk/), and the [MVP](https://www.research.va.gov/mvp/)  \n",
    "\n",
    "Phenotypes were modeled to reflect the actual genetic architecture of these complex traits as closely as possible. Most single variant association results should correspond well to published GWAS, but others may not. **Results produced from these data should not be taken as representing real, replicable genetic associations. These data are provided for demonstration and training purposes only.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install -U terra_notebook_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "from analysis_utils import AnalysisUtils\n",
    "from terra_notebook_utils import drs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## Set configuration\n",
    "\n",
    "Obtain a JWT by going through the auth flow here:\n",
    "\n",
    "https://tdrb2ctest.b2clogin.com/tdrb2ctest.onmicrosoft.com/oauth2/v2.0/authorize?p=B2C_1A_SIGNUP_SIGNIN&client_id=bc8119eb-e425-4ff7-945a-05f90a37fca7&nonce=defaultNonce&redirect_uri=https%3A%2F%2Fjwt.ms&scope=openid&response_type=id_token&prompt=login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Paste in the JWT token obtained via Azure B2C\n",
    "token = \"\"\n",
    "# Paste snapshot ID generated from the AzureY1Demo notebook\n",
    "snapshot_id = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load phenotypes \n",
    "\n",
    "Phenotypic data for each individual in the study are stored in Azure TDR. To analyze inside this notebook, we have to explicitly load the data in our notebook environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve TDR snapshot and copy parquet data to the notebook\n",
    "\n",
    "Note: this duplicates some functionality from the `AzureY1Demo` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = AnalysisUtils(token)\n",
    "snapshot = utils.snapshots_api().retrieve_snapshot(snapshot_id, include=[\"ACCESS_INFORMATION\"])\n",
    "table = next(iter(snapshot.access_information.parquet.tables), lambda t: t.name == \"demo_pheno_data\")\n",
    "local_parquet_dir = \"/tmp/az\"\n",
    "os.system(\"rm -r %s/%s.parquet\" % (local_parquet_dir, table.name))\n",
    "os.system(\"azcopy cp '%s?%s' '%s' --recursive\" % (table.url, table.sas_token, local_parquet_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phenotype data\n",
    "\n",
    "Load phenotype data into a pandas dataframe. The columns correspond to:  \n",
    "\n",
    "* **sample:** a unique label for each individual sample in our dataset\n",
    "* **age:** numerical age of the individual at the time of each phenotype measure\n",
    "* **ancestry:** superpopulation group of each individual\n",
    "  * AFR: African\n",
    "  * AMR: Ad Mixed American\n",
    "  * EAS: East Asian\n",
    "  * EUR: European\n",
    "  * SAS: South Asian\n",
    "* **bmi:** body mass index\n",
    "* **fg:** fasting glucose\n",
    "* **fi:** fasting insulin\n",
    "* **hdl:** high density lipoprotein\n",
    "* **height:** standing height\n",
    "* **ldl:** low density lipoprotein\n",
    "* **population:** population of each sample, see [1000 Genomes description](https://www.internationalgenome.org/category/population/)\n",
    "* **sex:** biological sex\n",
    "* **tc:** total cholesteral\n",
    "* **tg:** total triglycerides\n",
    "* **whr:** waist-to-hip ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_parquet(\"%s/%s.parquet\" % (local_parquet_dir, table.name))\n",
    "samples = samples.drop(columns=[\"datarepo_row_id\"])\n",
    "samples.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine phenotype data\n",
    "----\n",
    "\n",
    "Let's take a look at the phenotype distributions. In a GWAS - and statistical genetics more generally - we should always be on the lookout for correlations within our dataset. Correlations between phenotypic values can confound our analysis, leading to results that may not represent true genetic associations with our traits. Exploring these relationships may help in choosing a reasonable set of covariates to model.    \n",
    "\n",
    "We've included a number of plotting functions below to make this as easy as possible. Feel free to modify - or write your own functions - as you explore the data. \n",
    "\n",
    "\n",
    "## Goals of this section\n",
    "----\n",
    "    \n",
    "1. Visualize the distribution of phenotype values  \n",
    "    - Within each continuous trait (using the kdplot function)  \n",
    "    - Between two continuous traits (with the bivariateDistributionPlot function)\n",
    "2. Determine whether trait distributions follow patterns we might expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating distribution plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/tmajaria/ashg_2019_workshop/master/ldl_kdplot.png\" align=\"left\" width=\"20%\">\n",
    "\n",
    "***Univariate distributions*** are easily visualized in histograms or density plots. We provide a function (<font color='red'>kdplot</font>) that will generate both types of plots, overlayed in a single figure. A continuously-valued variable corresponding to a column in the phenotype dataframe should be used as input, *ldl* in this example. The function is called with the following syntax:\n",
    "\n",
    "```python\n",
    "kdPlot(samples, var = \"ldl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/tmajaria/ashg_2019_workshop/master/whr_hdl_bivariateDistributionPlot.png\" align=\"left\" width=\"20%\"> \n",
    "\n",
    "***Bivariate distributions*** can be visualized using a scatterplot. Use the function <font color='red'>bivariateDistributionPlot</font> to visualize two continuously values variables. The *type* argument determines the type of plot generated and can be one of: \"scatter\", \"reg\", \"resid\", \"kde\", and \"hex\".\n",
    "\n",
    "```python\n",
    "bivariateDistributionPlot(samples, var1 = \"hdl\", var2 = \"whr\", kind = \"scatter\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Univariate distributions\n",
    "\n",
    "Use the code cells below to plot the distribution of single variables of your choice (such as ldl or bmi). You may need to refer to section 3.2 above for the list of variables and to section 4.1 for the plotting syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.kdPlot(samples, var = \"ldl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Bivariate distributions\n",
    "\n",
    "Generate scatter plots with different combinations of variables. Think about what you would expect versus what you see in the plot. You may need to refer to 3.2 for the list of variables and to section 4.1 for the plotting syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.bivariateDistributionPlot(samples, var1 = \"bmi_baseline\", var2 = \"ldl\", kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at IGV\n",
    "----\n",
    "\n",
    "Just for fun, let's use the `igv-jupyter` notebook extension to look at genotype information for 1 sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DRS URLs from the sample table\n",
    "bam_file = samples.at[0, 'bam_file']\n",
    "bam_file_index = samples.at[0, 'bam_file_index']\n",
    "\n",
    "print(f'bam_file: {bam_file}')\n",
    "print(f'bam_file_index: {bam_file_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use terra-notebook-utils to resolve the DRS and download the data\n",
    "drs.copy_batch([bam_file, bam_file_index], \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up IGV\n",
    "\n",
    "import igv\n",
    "\n",
    "b = igv.Browser({\"genome\": \"hg38\"})\n",
    "\n",
    "b.load_track(\n",
    "  {\n",
    "    \"name\": \"HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20101123.bam\",\n",
    "    \"url\": \"HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20101123.bam\",\n",
    "    \"indexURL\": \"HG00096.chrom20.ILLUMINA.bwa.GBR.low_coverage.20101123.bam.bai\",\n",
    "    \"format\": \"bam\",\n",
    "    \"type\": \"alignment\"\n",
    "  }\n",
    ")\n",
    "\n",
    "b.search('chr20:32,214,217-32,229,950')\n",
    "\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
